{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nuScenes-devkit チュートリアル\n",
    "\n",
    "nuScenesのチュートリアルになります。\n",
    "\n",
    "### 前提\n",
    "[nuScenesサイト](https://www.nuscenes.org/nuscenes#download)からFull Dataset(v1.0)の Miniをダウンロードして中身を/data/sets/nuscenesに格納しておくこと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nuScenesデータセットとは\n",
    "\n",
    "Motional（以前のNutonomy）でチームが開発した自律運転のための公開大規模なデータセットです。 Motionalは、無人車両を安全で信頼性が高く、アクセスしやすい現実にしています。データのサブセットを一般に公開することにより、Motionalは、コンピュータービジョンと自律運転に関する公共研究をサポートすることを目指しています。\n",
    "\n",
    "nuScenesデータセットはボストンとシンガポールで1000の運転シーン(1シーン20秒)を収集しています。\n",
    "\n",
    "物体検出や追跡といったタスクに向けて、23のオブジェクトクラスにデータセット全体で2Hz周期で3D境界ボックスをアノテーションされています。\n",
    "\n",
    "nuScenesは6つのカメラ、1つのLidar、5つのレーダー、GPS、IMUからデータを提供する大規模なデータセットとなります。\n",
    "\n",
    "nuScenesセンサーレイアウトは公開されています。\n",
    "![](images/car_setup.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nuScenes データセットの簡単な紹介\n",
    "\n",
    "\n",
    "チュートリアルのこの部分では、データベースをトップダウンで紹介します。データセットは、次の基本的な要素を持つjsonファイルで構成されています。\n",
    "\n",
    "1. `log` - データが抽出されたログ情報。\n",
    "2. `scene` - 車の走行シーンの 20 秒の断片。\n",
    "3. `sample` - 特定のタイムスタンプにおけるシーンの注釈付きスナップショット。\n",
    "4. `sample_data` - 特定のセンサー(camera, lidar, radar)から収集されたデータ。\n",
    "5. `ego_pose` - 特定のタイムスタンプにおける自車両のポーズ。\n",
    "6. `sensor` - 特定のセンサータイプ。\n",
    "7. `calibrated sensors` - 特定の車両で調整された特定のセンサーの定義。\n",
    "8. `instance` - 観察したすべてのオブジェクト インスタンスの列挙。\n",
    "9. `category` - オブジェクト カテゴリの分類 (例: 車両、人間)。\n",
    "10. `attribute` - カテゴリは同じままで変更できるインスタンスのプロパティ。\n",
    "11. `visibility` - 6 台の異なるカメラから収集されたすべての画像で表示されるピクセルの割合。\n",
    "12. `sample_annotation` - 対象となるオブジェクトの注釈付きインスタンス。\n",
    "13. `map` - トップダウン ビューからバイナリ セマンティック マスクとして保存されるマップ データ。\n",
    "\n",
    "nuScenesスキーマは公式サイトで視覚化されています。詳細については[nuScenes schema](https://github.com/nutonomy/nuscenes-devkit/blob/master/docs/schema_nuscenes.md) ページを参照してください。\n",
    "![](https://www.nuscenes.org/public/images/nuscenes-schema.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境構築(jupyter, Google Colab)\n",
    "\n",
    "<br>\n",
    "<a href=\"https://colab.research.google.com/github/nutonomy/nuscenes-devkit/blob/master/python-sdk/tutorials/nuscenes_tutorial.ipynb\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" align=\"left\">\n",
    "</a>\n",
    "<br>\n",
    "\n",
    "ノートブックで実行している場合は、下のセルのコメントを解除して環境構築およびnuScenes-miniデータセットの取得を実行できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p /data/sets/nuscenes  # Make the directory to store the nuScenes dataset in.\n",
    "\n",
    "# !wget https://www.nuscenes.org/data/v1.0-mini.tgz  # Download the nuScenes mini split.\n",
    "\n",
    "# !tar -xf v1.0-mini.tgz -C /data/sets/nuscenes  # Uncompress the nuScenes mini split.\n",
    "\n",
    "# !pip install nuscenes-devkit &> /dev/null  # Install nuScenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot='/data/sets/nuscenes', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `scene`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuScenes は、それぞれ約20秒の ***1000シーン*** にわたるアノテーション付きサンプルを備えた大規模なデータベースです。読み込まれたデータベースにあるシーンを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.list_scenes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シーンのメタデータを見てみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scene = nusc.scene[0]\n",
    "my_scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `sample`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シーンでは、0.5 秒 (2 Hz) ごとにデータにアノテーションを付けます。\n",
    "\n",
    "`sample` を、***特定のタイムスタンプでのシーンの注釈付きキーフレーム*** として定義します。キーフレームとは、すべてのセンサーからのデータのタイムスタンプが、それが指すサンプルのタイムスタンプに非常に近いフレームです。\n",
    "\n",
    "では、このシーンの最初の注釈付きサンプルを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_sample_token = my_scene['first_sample_token']\n",
    "\n",
    "# The rendering command below is commented out because it tends to crash in notebooks\n",
    "# nusc.render_sample(first_sample_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メタデータを調べてみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_sample = nusc.get('sample', first_sample_token)\n",
    "my_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "便利なメソッドは `list_sample()` です。これは、`sample` に関連付けられたすべての関連する `sample_data` キーフレームと `sample_annotation` を一覧表示します。これについては、後続の部分で詳しく説明します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nusc.list_sample(my_sample['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. `sample_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuScenes データセットには、完全なセンサー スイートから収集されたデータが含まれています。したがって、シーンの各スナップショットに対して、これらのセンサーから収集されたデータ ファミリへの参照を提供します。\n",
    "\n",
    "これらにアクセスするための `data` キーを提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sample['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "キーは、センサー スイートを構成するさまざまなセンサーを参照していることに注意してください。`CAM_FRONT` から取得した `sample_data` のメタデータを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'CAM_FRONT'\n",
    "cam_front_data = nusc.get('sample_data', my_sample['data'][sensor])\n",
    "cam_front_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特定のセンサーで `sample_data` をレンダリングすることもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.render_sample_data(cam_front_data['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. `sample_annotation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample_annotation` は、***サンプル内に表示されるオブジェクトの位置を定義するバウンディングボックス*** を参照します。すべての位置データは、グローバル座標系を基準に与えられます。上記の `sample` の例を調べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_annotation_token = my_sample['anns'][18]\n",
    "my_annotation_metadata =  nusc.get('sample_annotation', my_annotation_token)\n",
    "my_annotation_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに詳しく見るためにアノテーションをレンダリングすることもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.render_annotation(my_annotation_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. `instance`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "オブジェクトインスタンスは、AVによって検出または追跡される必要があるインスタンスです（特定の車両、歩行者など）。インスタンスメタデータを調べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_instance = nusc.instance[599]\n",
    "my_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常、特定のシーン内の異なるフレームにわたってインスタンスを追跡します。ただし、異なるシーンにわたってインスタンスを追跡することはありません。この例では、特定のシーンにわたってこのインスタンスの注釈付きサンプルが 16 個あります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_token = my_instance['token']\n",
    "nusc.render_instance(instance_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "インスタンスレコードは最初と最後のアノテーショントークンを記録します。これらをレンダリングしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First annotated sample of this instance:\")\n",
    "nusc.render_annotation(my_instance['first_annotation_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Last annotated sample of this instance\")\n",
    "nusc.render_annotation(my_instance['last_annotation_token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. `category`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`カテゴリ` は、注釈のオブジェクト割り当てです。データベースにあるカテゴリ テーブルを見てみましょう。テーブルには、さまざまなオブジェクト カテゴリの分類が含まれており、サブカテゴリ (ピリオドで区切られています) もリストされています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.list_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カテゴリ レコードには、特定のカテゴリの名前と説明が含まれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.category[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さまざまなカテゴリの定義については、[nuscenes-devkit](https://github.com/nutonomy/nuscenes-devkit) の `instructions_nuscenes.md` を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. `attribute`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`属性` は、カテゴリは同じままで、シーンのさまざまな部分で変化する可能性があるインスタンスのプロパティです。ここでは、提供されている属性と、特定の属性に関連付けられている注釈の数をリストします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.list_attributes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1つのシーンで属性がどのように変化するかの例を見てみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_instance = nusc.instance[27]\n",
    "first_token = my_instance['first_annotation_token']\n",
    "last_token = my_instance['last_annotation_token']\n",
    "nbr_samples = my_instance['nbr_annotations']\n",
    "current_token = first_token\n",
    "\n",
    "i = 0\n",
    "found_change = False\n",
    "while current_token != last_token:\n",
    "    current_ann = nusc.get('sample_annotation', current_token)\n",
    "    current_attr = nusc.get('attribute', current_ann['attribute_tokens'][0])['name']\n",
    "    \n",
    "    if i == 0:\n",
    "        pass\n",
    "    elif current_attr != last_attr:\n",
    "        print(\"Changed from `{}` to `{}` at timestamp {} out of {} annotated timestamps\".format(last_attr, current_attr, i, nbr_samples))\n",
    "        found_change = True\n",
    "\n",
    "    next_token = current_ann['next']\n",
    "    current_token = next_token\n",
    "    last_attr = current_attr\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. `visibility`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`visibility` は、4 つのビンにグループ化された 6 つのカメラ フィード全体に表示される特定の注釈のピクセルの割合として定義されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visibilityが80～100%の`sample_annotation`の例を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anntoken = 'a7d0722bce164f88adf03ada491ea0ba'\n",
    "visibility_token = nusc.get('sample_annotation', anntoken)['visibility_token']\n",
    "\n",
    "print(\"Visibility: {}\".format(nusc.get('visibility', visibility_token)))\n",
    "nusc.render_annotation(anntoken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visibilityが0～40%の`sample_annotation`の例を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anntoken = '9f450bf6b7454551bbbc9a4c6e74ef2e'\n",
    "visibility_token = nusc.get('sample_annotation', anntoken)['visibility_token']\n",
    "\n",
    "print(\"Visibility: {}\".format(nusc.get('visibility', visibility_token)))\n",
    "nusc.render_annotation(anntoken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. `sensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuScenesデータセットは、「nuScenesデータセットとは」で説明した通り、以下のセンサースイートから収集されたデータで構成されています:\n",
    "- 1 x LIDAR、\n",
    "- 5 x RADAR、\n",
    "- 6 x カメラ、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nusc.sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すべての `sample_data` には、どの `sensor` からデータが収集されたかの記録があります (「channel」キーに注意してください)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nusc.sample_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. `calibrated_sensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calibrated_sensor` は、特定の車両で調整された特定のセンサー (LIDAR/レーダー/カメラ) の定義で構成されます。例を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nusc.calibrated_sensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`translation` および `rotation` パラメータは、自車両のボディ フレームに対して指定されることに注意してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. `ego_pose`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ego_pose` には、グローバル座標系に対する自車両の位置 (`translation` でエンコード) と方向 (`rotation` でエンコード) に関する情報が含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.ego_pose[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "読み込まれたデータベース内の `ego_pose` レコードの数は `sample_data` レコードの数と同じであることに注意してください。これら 2 つのレコードは 1 対 1 の対応を示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. `log`\n",
    "\n",
    "`log` テーブルには、データが抽出されたログ情報が含まれています。`log` レコードは、定義済みのルートに沿った自車の 1 回の走行に対応します。ログの数とログのメタデータを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of `logs` in our loaded database: {}\".format(len(nusc.log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.log[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ログが収集された日付や場所など、さまざまな情報が含まれていることに注意してください。また、データが収集されたマップの情報も表示されます。1 つのログに、重複しない複数のシーンを含めることができることに注意してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. `map`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "マップ情報は、トップダウンビューからバイナリセマンティックマスクとして保存されます。マップの数とマップのメタデータを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} maps masks in the loaded dataset\".format(len(nusc.map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nusc.map[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nuScenesの基本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "少し技術的な話に移ります。\n",
    "\n",
    "NuScenes クラスには複数のテーブルがあります。各テーブルはレコードのリストで、各レコードは辞書です。たとえば、カテゴリ テーブルの最初のレコードは次の場所に格納されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.category[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カテゴリ テーブルはシンプルです。`name` フィールドと `description` フィールドを保持します。また、一意のレコード識別子である `token` フィールドもあります。レコードは辞書なので、トークンには次のようにアクセスできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_token = nusc.category[0]['token']\n",
    "cat_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB内の任意のレコードの「トークン」がわかっている場合は、次のようにしてレコードを取得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.get('category', cat_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_お気づきのとおり、同じレコードが取得されました!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "はい、簡単でした。もっと難しいことに挑戦してみましょう。`sample_annotation` テーブルを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.sample_annotation[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これには `token` フィールドもあります (すべてに存在します)。さらに、[a-z]*\\_token 形式のフィールドがいくつかあります (例: instance_token)。これらはデータベース用語では外部キーであり、別のテーブルを指します。\n",
    "`nusc.get()` を使用すると、これらのいずれかを一定時間で取得できます。たとえば、visibilityのレコードを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.get('visibility', nusc.sample_annotation[0]['visibility_token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visibility レコードは、注釈が付けられたときにオブジェクトがどの程度可視であったかを示します。\n",
    "\n",
    "`instance_token` も取得しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_instance = nusc.get('instance', nusc.sample_annotation[0]['instance_token'])\n",
    "one_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは `instance` テーブルを指します。このテーブルは、各シーンで遭遇したオブジェクト _インスタンス_ を列挙します。このようにして、特定のオブジェクトのすべての注釈を接続できます。\n",
    "README テーブルをよく見ると、sample_annotation テーブルがインスタンス テーブルを指していることがわかりますが、インスタンス テーブルには、それを指すすべての注釈がリストされていません。\n",
    "では、特定のオブジェクト インスタンスのすべての sample_annotations を復元するにはどうすればよいでしょうか。方法は 2 つあります。\n",
    "\n",
    "1. `nusc.field2token()` を使用します。試してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_tokens = nusc.field2token('sample_annotation', 'instance_token', one_instance['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは、`'instance_token'` == `one_instance['token']` であるすべての sample_annotation レコードのリストを返します。これらをセットに保存しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ann_tokens_field2token = set(ann_tokens)\n",
    "\n",
    "ann_tokens_field2token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nusc.field2token()` メソッドは汎用的で、同様の状況で使用できます。\n",
    "\n",
    "2. 特定の状況では、テーブル自体に逆インデックスをいくつか提供します。これはその一例です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instance レコードには、このインスタンスの最初の注釈を指すフィールド `first_annotation_token` があります。\n",
    "このレコードの回復は簡単です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_record = nusc.get('sample_annotation', one_instance['first_annotation_token'])\n",
    "ann_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、「next」フィールドを使用してこのインスタンスのすべての注釈を走査できるようになりました。試してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_tokens_traverse = set()\n",
    "ann_tokens_traverse.add(ann_record['token'])\n",
    "while not ann_record['next'] == \"\":\n",
    "    ann_record = nusc.get('sample_annotation', ann_record['next'])\n",
    "    ann_tokens_traverse.add(ann_record['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、nusc.field2token を使用して実行したのと同じ ann_records が回復されたことを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ann_tokens_traverse == ann_tokens_field2token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逆インデックスとショートカット\n",
    "\n",
    "nuScenes テーブルは正規化されており、各情報は 1 回だけ提供されます。\n",
    "\n",
    "たとえば、各 `log` レコードには 1 つの `map` レコードがあります。スキーマを見ると、`map` テーブルには `log_token` フィールドがありますが、`log` テーブルには対応する `map_token` フィールドがないことがわかります。しかし、`log` があり、対応する `map` を見つけたい状況はたくさんあります。では、どうすればよいでしょうか。`nusc.field2token()` メソッドをいつでも使用できますが、これは遅くて不便です。そのため、このような状況を含むいくつかの一般的な状況に対して逆マッピングを追加します。\n",
    "\n",
    "さらに、特定の情報を取得するために複数のテーブルを調べる必要がある状況もあります。\n",
    "\n",
    "たとえば、`sample_annotation` のカテゴリ名 (例: `human.pedestrian`) を考えてみましょう。カテゴリはインスタンス レベルの定数であるため、`sample_annotation` テーブルにはこの情報は保持されません。代わりに、`sample_annotation` テーブルは `instance` テーブル内のレコードを指します。これは、`category` テーブル内のレコードを指し、最終的に `name` フィールドに必要な情報が格納されます。\n",
    "\n",
    "注釈のカテゴリ名を知りたいと思うことはよくあるため、NuScenes クラスの初期化中に `sample_annotation` テーブルに `category_name` フィールドを追加します。\n",
    "\n",
    "このセクションでは、初期化中に `NuScenes` クラスに追加されるショートカットと逆インデックスをリストします。これらはすべて `NuScenes.__make_reverse_index__()` メソッドで作成されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逆インデックス\n",
    "デフォルトで 2 つの逆インデックスを追加します。\n",
    "* `map_token` フィールドが `log` レコードに追加されます。\n",
    "* `sample` レコードには、そのレコードのすべての `sample_annotations` と `sample_data` キーフレームへのショートカットがあります。詳細については、前のセクションの `nusc.list_sample()` メソッドを参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ショートカット"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_annotation テーブルには「category_name」ショートカットがあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_ショートカットを使用_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catname = nusc.sample_annotation[0]['category_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_ショートカットを使用しない_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_rec = nusc.sample_annotation[0]\n",
    "inst_rec = nusc.get('instance', ann_rec['instance_token'])\n",
    "cat_rec = nusc.get('category', inst_rec['category_token'])\n",
    "\n",
    "print(catname == cat_rec['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_data テーブルには、「channel」と「sensor_modality」のショートカットがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortcut\n",
    "channel = nusc.sample_data[0]['channel']\n",
    "\n",
    "# No shortcut\n",
    "sd_rec = nusc.sample_data[0]\n",
    "cs_record = nusc.get('calibrated_sensor', sd_rec['calibrated_sensor_token'])\n",
    "sensor_record = nusc.get('sensor', cs_record['sensor_token'])\n",
    "\n",
    "print(channel == sensor_record['channel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの可視化\n",
    "\n",
    "リストとレンダリングのメソッドを提供します。これらは、開発中の便利なメソッドとして、また独自の視覚化メソッドを構築するためのチュートリアルとして意図されています。これらは NuScenesExplorer クラスに実装されており、NuScenes クラス自体を介したショートカットがあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### リスト メソッド\n",
    "使用可能なリスト メソッドは 3 つあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `list_categories()` は、幅/長さ/高さ（メートル）とアスペクト比のすべてのカテゴリ、カウント、統計を一覧表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.list_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `list_attributes()` はすべての属性とその数を一覧表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.list_attributes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `list_scenes()` は、ロードされた DB 内のすべてのシーンを一覧表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.list_scenes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、画像に LiDAR 点群をプロットしてみましょう。LiDAR を使用すると、周囲を 3D で正確にマッピングできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sample = nusc.sample[10]\n",
    "nusc.render_pointcloud_in_image(my_sample['token'], pointsensor_channel='LIDAR_TOP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前の画像では、色は自車両から各 LIDAR ポイントまでの距離を示しています。LIDAR の強度もレンダリングできます。次の画像では、前方の交通標識は反射率が高く (黄色)、右側の暗い車両は反射率が低く (紫色) なっています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.render_pointcloud_in_image(my_sample['token'], pointsensor_channel='LIDAR_TOP', render_intensity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、同じ画像のレーダー点群をプロットしてみましょう。レーダーは LIDAR よりも密度が低いですが、範囲がはるかに広くなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.render_pointcloud_in_image(my_sample['token'], pointsensor_channel='RADAR_FRONT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、そのサンプルのすべてのサンプルデータにわたるすべての注釈をプロットすることもできます。レーダーの場合、移動するオブジェクトの速度ベクトルもプロットされていることに注意してください。一部の速度ベクトルは外れ値であり、RadarPointCloud.from_file() の設定を使用してフィルタリングできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sample = nusc.sample[20]\n",
    "\n",
    "# The rendering command below is commented out because it may crash in notebooks\n",
    "# nusc.render_sample(my_sample['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "または、特定のセンサーのみをレンダリングしたい場合は、それを指定することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.render_sample_data(my_sample['data']['CAM_FRONT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに、複数のsweepsからの点群を集約して、より密度の高い点群を取得することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.render_sample_data(my_sample['data']['LIDAR_TOP'], nsweeps=5, underlay_map=True)\n",
    "nusc.render_sample_data(my_sample['data']['RADAR_FRONT'], nsweeps=5, underlay_map=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のレーダー プロットでは、2 台の車両からの非常に信頼性の高いレーダー リターンのみが表示されています。これは、ファイル `nuscenes/utils/data_classes.py` で定義されているフィルター設定によるものです。代わりに、すべてのフィルターを無効にしてすべてのリターンをレンダリングする場合は、`disable_filters()` 関数を使用できます。これにより、より密度の高いポイント クラウドが返されますが、背景のオブジェクトからのリターンが多くなります。デフォルト設定に戻すには、`default_filters()` を呼び出すだけです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.utils.data_classes import RadarPointCloud\n",
    "RadarPointCloud.disable_filters()\n",
    "nusc.render_sample_data(my_sample['data']['RADAR_FRONT'], nsweeps=5, underlay_map=True)\n",
    "RadarPointCloud.default_filters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特定の注釈を可視化することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.render_annotation(my_sample['anns'][22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、完全なシーンをビデオとして可視化できます。ここでは 2 つのオプションがあります:\n",
    "1. nusc.render_scene_channel() は、特定のチャネルのビデオを可視化します。(終了するには ESC キーを押します)\n",
    "2. nusc.render_scene() は、すべてのカメラ チャネルのビデオを可視化します。\n",
    "\n",
    "注: これらのメソッドは可視化に OpenCV を使用しますが、IPython Notebooks でうまく動作しない場合があります。問題が発生した場合は、コマンド ラインからこれらの行を実行してください。\n",
    "\n",
    "シーン 0061 を取得しましょう。これは素晴らしく密度の高いものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scene_token = nusc.field2token('scene', 'name', 'scene-0061')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rendering command below is commented out because it may crash in notebooks\n",
    "# nusc.render_scene_channel(my_scene_token, 'CAM_FRONT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、すべてのカメラ チャネルのビデオを可視化するメソッド nusc.render_scene() もあります。\n",
    "これには高解像度のモニターが必要であり、このノートブックの外部で実行するのが最適です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rendering command below is commented out because it may crash in notebooks\n",
    "# nusc.render_scene(my_scene_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、特定の場所のすべてのシーンを地図上に視覚化してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.render_egoposes_on_map(log_location='singapore-onenorth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
